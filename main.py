# main.py â€“ Stand: 02.05.2025
# ------------------------------------------------------------
# ðŸ”§ CLI-BefehlsÃ¼bersicht â€“ Firmware File Analyzer
#
# Standardanalyse (Basisfunktionen)
# ----------------------------------
# python main.py analyze --dir ./data
# python main.py analyze-pandas --dir ./data --export report.csv --format csv
# python main.py analyze-pandas --dir ./data --export stats.json --format json
# python main.py export-basic --dir ./data --output export.csv --format csv
#
# Interaktive Funktionen
# -----------------------
# python main.py clean-text
# python main.py search-text --dir ./data "ERROR"
#
# Visualisierung & erweiterte Analyse
# -----------------------------------
# python main.py visualize --dir ./data --export summary.csv --alert-threshold 10
# python main.py visualize-errors --filepath ./data/sensor_data_with_lots_errors.txt
# python main.py visualize-errors-all --filepath ./data/sensor_data_with_lots_errors.txt
#
# Fehlerreports (Export & PDF)
# -----------------------------
# python main.py generate-error-report --filepath ./data/sensor_data_with_lots_errors.txt
# python main.py generate-full-error-report --filepath ./data/sensor_data_with_lots_errors.txt
# python main.py generate-error-report-zip --filepath ./data/sensor_data_with_lots_errors.txt
#
# Kritische Fehlerzeitfenster filtern
# ------------------------------------
# python main.py find-critical-errors --filepath ./data/sensor_data_with_lots_errors.txt --error-type firmware_issue --threshold 4
# ------------------------------------------------------------


import typer
import logging
import os
import pandas as pd
from src.text_tool import remove_whitespace, word_count
from src.file_writer import export_to_csv, export_to_json
from src.file_reader import read_text_file
from src.log_util import setup_logger
from src.text_analyzer import TextAnalyzer
from src.visualizer import plot_analysis, plot_trends, plot_error_types
from src.data_analysis import (build_enhanced_dataframe, save_dataframe,
                               calculate_correlations, count_log_entries, classify_errors)
from src.error_visualizer import (plot_error_timecourse, plot_error_heatmap, export_error_report_to_pdf, export_report_as_zip,
                                  detect_critical_error_windows, publish_reports_to_docs, compare_error_logs,
                                  plot_error_comparison, plot_error_heatmap_logs, export_emba_report_to_pdf)
from src.error_timeparser import classify_error_type, extract_timestamp, build_error_dataframe
from src.emba_parser import (extract_summary_from_index, extract_cves_auto, extract_cves_from_f17, plot_top_cve_components)
from typing import Optional
from rich import print as rprint
from rich.text import Text
from rich.console import Console
from rich.table import Table


app = typer.Typer()
setup_logger()

@app.command()
def analyze(
    dir: str = typer.Option("./data","--dir","-d",help="Pfad zum Verzeichnis mit .txt-Dateien"),
    format: str = typer.Option("csv", help="Exportformat: csv oder json"),
    export: Optional[str] = typer.Option(None, help="Pfad zur Exportdatei (optional)")
):
    """Analysiert ein Verzeichnis mit .txt-Dateien."""
    all_entries = []
    for fname in os.listdir(dir):
        if fname.endswith(".txt"):
            path = os.path.join(dir, fname)
            with open(path, encoding="utf-8") as f:
                content = f.read()
            lines = content.splitlines()
            error_df = build_error_dataframe(lines)
            if error_df.empty:
                continue
            error_df["source_file"] = fname
            all_entries.append(error_df)

    if not all_entries:
        print("âš ï¸ Keine gÃ¼ltigen Fehlerdaten gefunden.")
        raise typer.Exit()

    result_df = pd.concat(all_entries)
    print(result_df.head())


    if export:
        export_dir = os.path.dirname(export)
        if export_dir:
            os.makedirs(export_dir, exist_ok=True)
        if format == "csv":
            export_to_csv(result_df, export)
            print(f"âœ… CSV exportiert: {export}")
        elif format == "json":
            export_to_json(result_df, export)
            print(f"âœ… JSON exportiert: {export}")
        else:
            print(f"âŒ Unbekanntes Format: {format}")

    
@app.command()
def search_text(
    dir: str = typer.Option("./data", "--dir", "-d", help="Verzeichnis mit .txt-Dateien"),
    term: str = typer.Argument(..., help="Suchbegriff (nicht case-sensitiv)")
):
    """Durchsucht alle .txt-Dateien im Verzeichnis nach einem Begriff (case-insensitive, farbig hervorgehoben)."""
    if not os.path.exists(dir):
        typer.echo(f"âŒ Fehler: Verzeichnis nicht gefunden: {dir}")
        raise typer.Exit(code=1)

    term_lower = term.lower()
    match_found = False

    for filename in os.listdir(dir):
        if filename.endswith(".txt"):
            path = os.path.join(dir, filename)
            try:
                with open(path, "r", encoding="utf-8") as f:
                    lines = f.readlines()
                    for i, line in enumerate(lines, start=1):
                        if term_lower in line.lower():
                            if not match_found:
                                rprint(f"\n[bold green]ðŸ” Ergebnisse fÃ¼r Suchbegriff:[/] '[bold yellow]{term}[/]'\n")
                                match_found = True

                            # farbiges Hervorheben des Treffers
                            line_text = Text(line.strip(), style="white")
                            start = line.lower().find(term_lower)
                            end = start + len(term)
                            if start >= 0:
                                line_text.stylize("bold red on white", start, end)

                            rprint(f"[cyan]ðŸ“„ {filename}[/] â€“ Zeile {i}: {line_text}")
            except Exception as e:
                typer.echo(f"âš ï¸ Fehler beim Lesen von {filename}: {e}")

    if not match_found:
        typer.echo(f"âŒ Keine Treffer fÃ¼r '{term}' in {dir}")

@app.command()
def clean_text(
    text: Optional[str] = typer.Argument(
        None,
        help="Text, der bereinigt und analysiert werden soll"
    )
):
    """Entfernt Ã¼berflÃ¼ssige Leerzeichen und zÃ¤hlt WÃ¶rter."""
    if text is None:
        text = typer.prompt("ðŸ”¤ Bitte gib einen Text ein")

    cleaned = remove_whitespace(text)
    print(f"Bereinigt: '{cleaned}'")
    print(f"Wortanzahl: {word_count(cleaned)}")
    logging.info("Textoperation durchgefÃ¼hrt: remove_whitespace + word_count")


@app.command()
def analyze_pandas(
    dir: str = typer.Option(
        "./data", "--dir", "-d",
        help="Pfad zum Verzeichnis mit .txt-Dateien"
    ),
    export: str = typer.Option(
        "report.csv", "--export", "-e",
        help="Pfad zur Ausgabedatei"
    ),
    format: str = typer.Option(
        "csv", "--format", "-f",
        help="Exportformat: csv oder json"
    )
):
    """Analysiert mit pandas-Erweiterung und exportiert als CSV oder JSON."""
    if not os.path.exists(dir):
        typer.echo(f"âŒ Fehler: Verzeichnis nicht gefunden: {dir}")
        raise typer.Exit(code=1)

    analyzer = TextAnalyzer(dir)
    if analyzer.collect_files():
        analyzer.analyze()
        analyzer.report()
        analyzer.report_pandas(export_path=export, file_format=format)

@app.command()
def check_firmware_status(
    filepath: str = typer.Option(..., help="Pfad zur Logdatei (.txt) mit Zeitstempeln und Fehlern")
):
    """
    PrÃ¼ft automatisch, ob die Firmware anhand des Fehlerlogs fÃ¼r das Deployment geeignet ist.
    """
    from src.error_timeparser import build_error_dataframe
    from src.emba_parser import evaluate_firmware_acceptance

    if not os.path.exists(filepath):
        print(f"âŒ Datei nicht gefunden: {filepath}")
        raise typer.Exit()

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)
    status, reason = evaluate_firmware_acceptance(df)

    print("\nðŸ“‹ Deployment-Entscheidung:")
    if status:
        print("âœ… Firmware FREIGEGEBEN")
    else:
        print("âŒ Firmware BLOCKIERT")
    print(f"BegrÃ¼ndung: {reason}")


@app.command()
def export_basic(
    dir: str = typer.Option("./data", "--dir", "-d", help="Verzeichnis mit .txt-Dateien"),
    output: str = typer.Option("export_light.csv", "--output", "-o", help="Ziel-Dateiname"),
    format: str = typer.Option("csv", "--format", "-f", help="Exportformat: csv oder json")
):
    """Exportiert Analyseergebnisse ohne pandas â€“ als CSV oder JSON."""
    if not os.path.exists(dir):
        typer.echo(f"âŒ Fehler: Verzeichnis nicht gefunden: {dir}")
        raise typer.Exit(code=1)

    # ðŸ§  Dateien analysieren wie in TextAnalyzer, aber leichtgewichtig:
    stats = []
    for filename in os.listdir(dir):
        if filename.endswith(".txt"):
            path = os.path.join(dir, filename)
            text = read_text_file(path)
            if text:
                stats.append({
                    "filename": filename,
                    "lines": text.count('\n') + 1,
                    "words": word_count(text),
                    "chars": len(text),
                    "bytes": os.path.getsize(path)
                })

    # ðŸ“¦ Export je nach Format:
    if format == "json":
        export_to_json(stats, output)
    else:
        export_to_csv(stats, output)


@app.command()
def visualize(
    dir: str = "./data",
    export: str = typer.Option(None, "--export", "-e", help="Exportiere erweiterten DataFrame (Pfad zu .csv oder .json)"),
    alert_threshold: float = typer.Option(10.0, "--alert-threshold", "-a", help="Fehlerquote-Schwelle fÃ¼r Warnungen (%)")
):
    """Erstellt Visualisierungen auf Basis der .txt-Analysen."""
    analyzer = TextAnalyzer(dir)
    if analyzer.collect_files():
        analyzer.analyze()
        data = []
        for filename in analyzer.txt_files:
            path = os.path.join(dir, filename)
            text = read_text_file(path)
            errors, warnings, infos = count_log_entries(text) if text else (0, 0, 0)
            error_classes = classify_errors(text) if text else {}

            # Berechnung der Statistiken
            data.append({
                "filename": filename,
                "lines": text.count('\n') + 1 if text else 0,
                "words": word_count(text) if text else 0,
                "chars": len(text) if text else 0,
                "bytes": os.path.getsize(path) if os.path.exists(path) else 0,
                "errors": errors,
                "warnings": warnings,
                "infos": infos,
                "sensor_errors": error_classes.get("sensor_error", 0),
                "voltage_warnings": error_classes.get("voltage_warning", 0),
                "communication_errors": error_classes.get("communication_error", 0),
                "firmware_issues": error_classes.get("firmware_issue", 0),
                "collision_errors": error_classes.get("collision_error", 0),
                "sensor_error":     error_classes.get("sensor_error", 0),
                "voltage_warning":  error_classes.get("voltage_warning", 0),
                "communication_error": error_classes.get("communication_error", 0),
                "firmware_issue":   error_classes.get("firmware_issue", 0),
                "collision_error":  error_classes.get("collision_error", 0)
            })
        plot_analysis(data)
        plot_error_types(data)
        # Ausgabe der Statistiken im Terminal       

        # Erstellen des erweiterten DataFrames
        enhanced_df = build_enhanced_dataframe(data)
        # Ausgabe des erweiterten DataFrames im Terminal
        #typer.echo("\nðŸ“ˆ Erweiterte Analyse:\n")
        #typer.echo(enhanced_df.to_string(index=False))

        console = Console()

        # Ausgabe schÃ¶ner formatieren mit Rich-Table
        table = Table(title="ðŸ“ˆ Erweiterte Analyse der Textdateien", header_style="bold cyan")

        # Spalten dynamisch aus dem DataFrame Ã¼bernehmen
        for col in enhanced_df.columns:
            table.add_column(str(col), justify="right")

        # Zeilen ausfÃ¼llen
        for _, row in enhanced_df.iterrows():
            row_values = []
            for col_name in enhanced_df.columns:
                value = row[col_name]
                if col_name == "error_rate_percent" and value > 10:
                    row_values.append(f"[bold red]{value:.2f} âš ï¸[/bold red]")
                else:
                    row_values.append(str(value))
            table.add_row(*row_values)


        console.print(table)

        plot_trends(data)
        correlations = calculate_correlations(data)

        console = Console()
        console.print("\nðŸ“Š [bold magenta]Korrelationsmatrix:[/bold magenta]")
        console.print(correlations)

        # Zusammenfassung: Anzahl kritischer Dateien
        critical_files = enhanced_df[enhanced_df["error_rate_percent"] > alert_threshold]
        
        if not critical_files.empty:
            console.print(f"\n[bold red]âš ï¸ {len(critical_files)} Datei(en) mit Fehlerquote > {alert_threshold:.1f} % erkannt:[/bold red]")
            for filename in critical_files["filename"]:
                console.print(f" - [yellow]{filename}[/yellow]")
        else:
            console.print(f"\n[bold green]âœ… Keine kritischen Fehlerquoten Ã¼ber {alert_threshold:.1f} % erkannt.[/bold green]")


        # Export, wenn Option angegeben ist
        if export:
            save_dataframe(enhanced_df, export)

        typer.echo("âœ… Visualisierungen wurden erfolgreich erstellt und gespeichert.")


        # Fehlerzeitverlauf analysieren
@app.command()
def visualize_errors(
    filepath: str = "./data/sensor_data_with_lots_errors.txt"
):
    """Visualisiert den Fehlerzeitverlauf einer Logdatei mit Zeitstempeln und Fehlerarten."""
    if not os.path.exists(filepath):
        print(f"Datei nicht gefunden: {filepath}")
        return

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)

    # Info-Zeilen ggf. filtern
    df = df[df["error_type"] != "info"]

    # Zeitverlauf plotten
    plot_error_timecourse(df)



@app.command()
def visualize_errors_all(
    filepath: str = "./data/sensor_data_with_lots_errors.txt"
):
    """
    FÃ¼hrt vollstÃ¤ndige Fehlerzeit-Visualisierung aus (Balken, Linie, Heatmap).
    """
    if not os.path.exists(filepath):
        print(f"Datei nicht gefunden: {filepath}")
        return

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)
    df = df[df["error_type"] != "info"]

    plot_error_timecourse(df)
    plot_error_heatmap(df)

@app.command()
def generate_error_report(
    filepath: str = "./data/sensor_data_with_lots_errors.txt"
):
    """
    Erstellt vollstÃ¤ndige Fehlerauswertung inkl. PDF-Report.
    """
    if not os.path.exists(filepath):
        print(f"âŒ Datei nicht gefunden: {filepath}")
        return

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)
    df = df[df["error_type"] != "info"]

    plot_error_timecourse(df)
    export_error_report_to_pdf()

@app.command()
def generate_full_error_report(
    filepath: str = "./data/sensor_data_with_lots_errors.txt"
):
    """
    Erstellt vollstÃ¤ndige Fehleranalyse mit PDF-Report inklusive Heatmap und kritischer Zusammenfassung.
    """
    if not os.path.exists(filepath):
        print(f"âŒ Datei nicht gefunden: {filepath}")
        return

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)
    df = df[df["error_type"] != "info"]

    plot_error_timecourse(df)
    plot_error_heatmap(df)
    export_error_report_to_pdf(df)

@app.command()
def generate_error_report_zip(
    filepath: str = "./data/sensor_data_with_lots_errors.txt"
):
    """
    Erstellt vollstÃ¤ndigen Fehlerbericht inkl. ZIP-Export aller Ausgabedateien.
    """
    if not os.path.exists(filepath):
        print(f"âŒ Datei nicht gefunden: {filepath}")
        return

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)
    df = df[df["error_type"] != "info"]

    plot_error_timecourse(df)
    plot_error_heatmap(df)
    export_error_report_to_pdf(df)
    export_report_as_zip()

@app.command()
def find_critical_errors(
    filepath: str = "./data/sensor_data_with_lots_errors.txt",
    error_type: str = "firmware_issue",
    threshold: int = 3
):
    """
    Zeigt alle Stunden, in denen ein bestimmter Fehlertyp hÃ¤ufiger als 'threshold' auftrat.
    """
    if not os.path.exists(filepath):
        print(f"âŒ Datei nicht gefunden: {filepath}")
        return

    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    df = build_error_dataframe(lines)
    df = df[df["error_type"] != "info"]

    filtered = detect_critical_error_windows(df, threshold=threshold)
    result = filtered[filtered["error_type"] == error_type]

    if result.empty:
        print(f"Keine Zeitfenster mit mehr als {threshold} Vorkommen von '{error_type}' gefunden.")
    else:
        print(f"âš ï¸ Kritische Zeitfenster fÃ¼r '{error_type}' (â‰¥ {threshold} Fehler):\n")
        print(result.to_string(index=False))


@app.command()
def publish_docs():
    """
    Kopiert alle aktuellen Report-Dateien nach docs/reports zur VerÃ¶ffentlichung.
    """
    publish_reports_to_docs()


@app.command()
def compare_logs(directory: str = "./data"):
    """
    Vergleicht Fehlerarten Ã¼ber mehrere Logdateien im angegebenen Verzeichnis.
    """
    df = compare_error_logs(directory)
    print(df)

@app.command()
def plot_error_comparison_chart(directory: str = "./data"):
    """
    Erstellt einen gruppierten Balkenplot zur Fehlerverteilung pro Logdatei.
    """
    df = compare_error_logs(directory)
    plot_error_comparison(df)

@app.command()
def plot_error_heatmap_chart(directory: str = "./data"):
    """
    Erstellt eine Heatmap der Fehlerarten Ã¼ber mehrere Logdateien.
    """
    df = compare_error_logs(directory)
    plot_error_heatmap_logs(df)


@app.command()
def interactive_report():
    """GefÃ¼hrter Ablauf zur Erstellung eines Fehler-Reports aus mehreren Logdateien."""
    typer.echo("ðŸ§­ Interaktiver Reportgenerator gestartet")
    directory = typer.prompt("ðŸ“ Verzeichnis mit Logdateien", default="./data")
    df = compare_error_logs(directory)

    if typer.confirm("ðŸ” Fehlervergleich anzeigen?"):
        typer.echo(df)

    if typer.confirm("ðŸ“Š Gruppierten Balkenplot erstellen?"):
        plot_error_comparison(df)

    if typer.confirm("ðŸ”¥ Heatmap erstellen?"):
        plot_error_heatmap_logs(df)

    if typer.confirm("ðŸ“„ PDF-Report exportieren?"):
        export_error_report_to_pdf(df)

    if typer.confirm("ðŸ—œï¸ ZIP-Export erzeugen?"):
        export_report_as_zip()

    if typer.confirm("ðŸŒ In docs/reports verÃ¶ffentlichen?"):
        publish_reports_to_docs()

    typer.echo("âœ… Interaktive Reportgenerierung abgeschlossen.")


@app.command()
def analyze_emba(
    filepath: str = typer.Option(..., help="Pfad zur index.html von EMBA"),
    export: Optional[str] = typer.Option(None, help="Pfad zur Exportdatei (csv/json)")
):
    """Analysiert EMBA index.html und extrahiert relevante Sicherheitsergebnisse."""
    from src.emba_parser import extract_summary_from_index

    df = extract_summary_from_index(filepath)
    print(df)

    if export:
        from src.file_writer import export_to_csv, export_to_json
        if export.endswith(".csv"):
            export_to_csv(df, export)
        elif export.endswith(".json"):
            export_to_json(df, export)
        else:
            print("âŒ Nur .csv oder .json unterstÃ¼tzt.")


@app.command()
def analyze_emba_cves(
    filepath: str = typer.Option(..., help="Pfad zur index.html oder f17_cve_bin_tool.html"),
    export: Optional[str] = typer.Option(None, help="Exportpfad fÃ¼r CSV"),
    min_cves: int = typer.Option(0, help="Minimale Anzahl CVEs fÃ¼r Filterung"),
    min_exploits: int = typer.Option(0, help="Minimale Anzahl Exploits fÃ¼r Filterung")
):
    """
    Extrahiert Komponenten-CVEs + Zusammenfassung aus EMBA HTML.
    Optional filterbar nach minimaler Anzahl an CVEs und Exploits.
    """
    from src.emba_parser import extract_cves_auto, assign_risk_level, plot_risk_level_distribution
    from src.file_writer import export_to_csv

    components_df, summary_df = extract_cves_auto(filepath)

    # ðŸ” Filter anwenden
    filtered_df = components_df[
        (components_df["cves"] >= min_cves) &
        (components_df["exploits"] >= min_exploits)
    ]

    filtered_df = assign_risk_level(filtered_df)
    plot_risk_level_distribution(filtered_df)
    #print("\nðŸ”¸ Risikostufenverteilung:\n")

    print("ðŸ”¹ Gefilterte Komponenten mit CVEs und Risikostufenverteilung:\n", filtered_df.head())
    #print("\nðŸ”¸ CVE-Zusammenfassung:\n", summary_df.to_string(index=False))

    if export:
        export_to_csv(filtered_df, export)
        


"""
@app.command()
def generate_emba_report(
    filepath: str = typer.Option(..., help="Pfad zur index.html oder f17_cve_bin_tool.html")
):
"""
    #Erstellt einen EMBA-spezifischen PDF-Report mit CVE-Charts und Zusammenfassung.
"""
    
    components_df, summary_df = extract_cves_auto(filepath)

    chart_path = "./charts/emba_top_cves.png"
    plot_top_cve_components(components_df, output_path=chart_path)
    export_emba_report_to_pdf(summary_df, chart_path)
"""

@app.command()
def generate_emba_report_full(
    filepath: str = typer.Option(..., help="Pfad zur EMBA index.html"),
):
    """
    Erstellt einen vollstÃ¤ndigen PDF-Report mit Chart, CVE-Summary und Komponententabelle.

    """
    from src.emba_parser import extract_cves_auto, assign_risk_level, plot_top_cve_components, plot_risk_level_distribution
    from src.error_visualizer import export_emba_report_to_pdf
    
    components_df, summary_df = extract_cves_auto(filepath)
    components_df = assign_risk_level(components_df)

    plot_top_cve_components(components_df)
    plot_risk_level_distribution(components_df)

    chart_path = "./charts/emba_top_cves.png"
    pdf_path = "./charts/errors/emba_report_full.pdf"
    export_emba_report_to_pdf(summary_df, chart_path, components_df, pdf_path)

@app.command()
def zip_emba_report(
    basepath: str = typer.Option("./charts/errors", help="Verzeichnis mit EMBA-Reportdaten")
):
    """
    Packt PDF, Chart und ggf. CSV-Dateien des EMBA-Reports in ein ZIP.
    """
    from src.error_visualizer import export_emba_report_zip

    files = [
        os.path.join(basepath, "emba_report_full.pdf"),
        "./charts/emba_top_cves.png",
        "emba_components.csv",
        "emba_components_summary.csv"
    ]
    export_emba_report_zip(files)


@app.command()
def plot_emba_heatmap(
    filepath: str = typer.Option(..., help="Pfad zur EMBA index.html oder f17_cve_bin_tool.html")
):
    """
    Erstellt eine Heatmap der CVEs und Exploits pro Komponente.
    """
    from src.emba_parser import extract_cves_auto, plot_cve_heatmap

    components_df, _ = extract_cves_auto(filepath)
    plot_cve_heatmap(components_df)

@app.command()
def gui_loganalyzer():
    """
    Startet die Streamlit-GUI zur Logfile-Analyse.
    """
    import subprocess
    import sys
    subprocess.run(["streamlit", "run", "experimental/gui/gui_streamlit_loganalyzer.py"])
    



if __name__ == "__main__":
    app()
